# Technical Report

## Storage

## Network

## XPU

> #### What is processing unit？
>常见的 CPU，GPU 中的 PU（Processing Unit) 是处理单元的意思。在一般的认知之中，CPU 负责处理程序运行的各种运算处理，而 GPU 则专门负责图形图像方面的处理和输出。随着AI 的热潮，又涌现出了 TPU 和 NPU 等等处理单元，他们都针对机器学习有着不同方面的优化，更符合专属的运用场景。接下来我们会以 GPU 和 TPU 为例，分别分析他们的特点和特定用途
---

### GPU
---
#### Introduction
GPU( Graphic Processing Unit)，是为了减轻 CPU 的图像处理压力而专门设计出来的图像处理器。

### Features
* 运算资源非常丰富
* 控制部件占的面积比较小内存带宽大，目前独显都采用 GDDR5 显存，位宽也高，主流独显内存带宽是CPU的十倍（200GB/s 对比 20GB）
* 内存延迟高，对比 CPU 使用多级缓存掩盖延迟，GPU 采用多线程掩盖延迟
* 寄存器资源极为丰富，32bit 寄存器有 64k 个，单线程可用 255 个


#### Pros
与特点相对应的，GPU 的优点在于数据吞吐量大，并行计算能力高
#### Cons
Latency 很高，不适合处理大量的分支
需要高度的数据对齐

#### Indicators
* **GPU浮点计算能力**：浮点计算能力是科学计算关注的重点，是衡量GPU协处理器性能的最重要指标

* **GPU访存带宽**：计算核心对内存（显存）和各级缓存（存储）的读写能力

* **GPU通信带宽**：GPU是协处理器，与CPU端存储是分离的，故GPU运算时必须先将CPU端的代码和数据传输到GPU，GPU才能执行kernel函数。涉及CPU 与GPU通信，其中通信接口PCI-E的版本和性能会直接影响通信带宽，此外，主机端口内存分页方式也将直接影响通信带宽

#### Application
* 图形计算
GPU 设计之处就是为了让 CPU 从繁重的图形计算之中解放出来，各司其职

* Deep Learning
用于图形计算的 GPU 有着极高的计算能力、并行计算能力和数据吞吐量，同时图形计算中的矩阵运算可以完成深度学习中卷积神经网络中的卷积运算和矩阵运算。所以深度学习可以通过 GPU 来进行加速。

### TPU
---
#### Introduction
TPU（Tensor Processing Unit）: Google为机器学习定制的专用芯片（ASIC），专为Google的深度学习框架TensorFlow而设计。

#### Features
与图形处理器（GPU）相比，TPU采用低精度（8位）计算，以降低每步操作使用的晶体管数量。降低精度对于深度学习的准确度影响很小，但却可以大幅降低功耗、加快运算速度。同时，TPU使用了脉动阵列的设计，用来优化矩阵乘法与卷积运算，减少I/O操作。此外，TPU还采用了更大的片上内存，以此减少对DRAM的访问，从而更大程度地提升性能。

#### Indicators
* **浮点计算能力**：每个 Cloud TPU 可提供最高每秒 180 万亿次浮点运算的计算性能
* **内存的带宽**：每个 Cloud TPU 可提供最高 64 GB 的超高带宽内存。
#### Application
谷歌用 TPU 来加速机器学习，并搭建了 Cloud TPU 平台来增强自己的云服务

